{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aef1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.6885\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9512 | Slot P: 0.3192 R: 0.3192 F1: 0.3192\n",
      "Epoch 2 | Train Loss: 0.4813\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9756 | Slot P: 0.3321 R: 0.3321 F1: 0.3321\n",
      "Epoch 3 | Train Loss: 0.2780\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9800 | Slot P: 0.3440 R: 0.3440 F1: 0.3440\n",
      "Epoch 4 | Train Loss: 0.1771\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3485 R: 0.3485 F1: 0.3485\n",
      "Epoch 5 | Train Loss: 0.1235\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9823 | Slot P: 0.3498 R: 0.3498 F1: 0.3498\n",
      "Epoch 6 | Train Loss: 0.0924\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9867 | Slot P: 0.3522 R: 0.3522 F1: 0.3522\n",
      "Epoch 7 | Train Loss: 0.0744\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9867 | Slot P: 0.3519 R: 0.3519 F1: 0.3519\n",
      "Epoch 8 | Train Loss: 0.0464\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3526 R: 0.3526 F1: 0.3526\n",
      "Epoch 9 | Train Loss: 0.0334\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9867 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 10 | Train Loss: 0.0307\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9823 | Slot P: 0.3521 R: 0.3521 F1: 0.3521\n",
      "Epoch 11 | Train Loss: 0.0235\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 12 | Train Loss: 0.0156\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3536 R: 0.3536 F1: 0.3536\n",
      "Epoch 13 | Train Loss: 0.0125\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3549 R: 0.3549 F1: 0.3549\n",
      "Epoch 14 | Train Loss: 0.0103\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 15 | Train Loss: 0.0083\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 16 | Train Loss: 0.0069\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 17 | Train Loss: 0.0059\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 18 | Train Loss: 0.0054\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 19 | Train Loss: 0.0044\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3539 R: 0.3539 F1: 0.3539\n",
      "Epoch 20 | Train Loss: 0.0041\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3537 R: 0.3537 F1: 0.3537\n",
      "Epoch 21 | Train Loss: 0.0267\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3528 R: 0.3528 F1: 0.3528\n",
      "Epoch 22 | Train Loss: 0.0176\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9867 | Slot P: 0.3539 R: 0.3539 F1: 0.3539\n",
      "Epoch 23 | Train Loss: 0.0068\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9800 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 24 | Train Loss: 0.0088\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9601 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 25 | Train Loss: 0.0278\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9867 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 26 | Train Loss: 0.0099\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 27 | Train Loss: 0.0060\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 28 | Train Loss: 0.0032\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 29 | Train Loss: 0.0025\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9889 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 30 | Train Loss: 0.0024\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3545 R: 0.3545 F1: 0.3545\n",
      "Epoch 31 | Train Loss: 0.0021\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 32 | Train Loss: 0.0019\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 33 | Train Loss: 0.0017\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 34 | Train Loss: 0.0016\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 35 | Train Loss: 0.0015\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 36 | Train Loss: 0.0013\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3545 R: 0.3545 F1: 0.3545\n",
      "Epoch 37 | Train Loss: 0.0011\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 38 | Train Loss: 0.0010\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 39 | Train Loss: 0.0010\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3549 R: 0.3549 F1: 0.3549\n",
      "Epoch 40 | Train Loss: 0.0008\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9911 | Slot P: 0.3541 R: 0.3541 F1: 0.3541\n",
      "Epoch 41 | Train Loss: 0.0009\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3551 R: 0.3551 F1: 0.3551\n",
      "Epoch 42 | Train Loss: 0.0008\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 43 | Train Loss: 0.0010\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3545 R: 0.3545 F1: 0.3545\n",
      "Epoch 44 | Train Loss: 0.0010\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 45 | Train Loss: 0.0006\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3547 R: 0.3547 F1: 0.3547\n",
      "Epoch 46 | Train Loss: 0.0007\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 47 | Train Loss: 0.0005\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3545 R: 0.3545 F1: 0.3545\n",
      "Epoch 48 | Train Loss: 0.0006\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3545 R: 0.3545 F1: 0.3545\n",
      "Epoch 49 | Train Loss: 0.0006\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "Epoch 50 | Train Loss: 0.0006\n",
      "=== Validation ===\n",
      "Intent Acc: 0.9933 | Slot P: 0.3543 R: 0.3543 F1: 0.3543\n",
      "=== Test Set Evaluation ===\n",
      "Intent Acc: 0.9920 | Slot P: 0.3984 R: 0.3984 F1: 0.3984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9920424403183024,\n",
       " 0.39835267690003745,\n",
       " 0.39835267690003745,\n",
       " 0.39835267690003745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "all_tokens = []\n",
    "for sentence in train_df['text']:\n",
    "    all_tokens.extend(sentence.split())\n",
    "vocab = sorted(set(all_tokens))\n",
    "word2idx = {\"<pad>\":0, \"<unk>\":1}\n",
    "for i, w in enumerate(vocab, start=2):\n",
    "    word2idx[w] = i\n",
    "with open(\"word2idx.json\", \"w\") as f:\n",
    "    json.dump(word2idx, f)\n",
    "\n",
    "\n",
    "all_slots = set()\n",
    "for slots in train_df['slots']:\n",
    "    all_slots.update(slots.split())\n",
    "slot2id = {\"O\":0}\n",
    "i = 1\n",
    "for s in all_slots:\n",
    "    if s != \"O\":\n",
    "        slot2id[s] = i\n",
    "        i +=1\n",
    "with open(\"slot2id.json\", \"w\") as f:\n",
    "    json.dump(slot2id, f)\n",
    "\n",
    "\n",
    "all_intents = train_df['intent'].unique()\n",
    "intent2id = {intent:i for i,intent in enumerate(all_intents)}\n",
    "with open(\"intent2id.json\", \"w\") as f:\n",
    "    json.dump(intent2id, f)\n",
    "\n",
    "id2slot = {v:k for k,v in slot2id.items()}\n",
    "id2intent = {v:k for k,v in intent2id.items()}\n",
    "\n",
    "class ATISDataset(Dataset):\n",
    "    def __init__(self, df, word2idx, slot2id, intent2id, max_len=50):\n",
    "        self.df = df\n",
    "        self.word2idx = word2idx\n",
    "        self.slot2id = slot2id\n",
    "        self.intent2id = intent2id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.df.iloc[idx]['text'].split()\n",
    "        slots = self.df.iloc[idx]['slots'].split()\n",
    "        intent = self.df.iloc[idx]['intent']\n",
    "\n",
    "        length = len(tokens)\n",
    "        input_ids = [self.word2idx.get(t, self.word2idx[\"<unk>\"]) for t in tokens]\n",
    "        slot_ids = [self.slot2id.get(s, 0) for s in slots]\n",
    "        intent_id = self.intent2id[intent]\n",
    "\n",
    "        pad_len = self.max_len - length\n",
    "        input_ids += [self.word2idx[\"<pad>\"]] * pad_len\n",
    "        slot_ids += [0] * pad_len\n",
    "\n",
    "        return torch.tensor(input_ids), torch.tensor(length), torch.tensor(slot_ids), torch.tensor(intent_id)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[0] for item in batch])\n",
    "    lengths = torch.tensor([item[1] for item in batch])\n",
    "    slot_labels = torch.stack([item[2] for item in batch])\n",
    "    intent_labels = torch.stack([item[3] for item in batch])\n",
    "    return input_ids, lengths, slot_labels, intent_labels\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = ATISDataset(train_df, word2idx, slot2id, intent2id)\n",
    "val_dataset = ATISDataset(val_df, word2idx, slot2id, intent2id)\n",
    "test_dataset = ATISDataset(test_df, word2idx, slot2id, intent2id)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "class JointRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, slot_label_size, intent_label_size, dropout=0.3):\n",
    "        super(JointRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.RNN(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.slot_classifier = nn.Linear(hidden_dim*2, slot_label_size)\n",
    "        self.intent_classifier = nn.Linear(hidden_dim*2, intent_label_size)\n",
    "\n",
    "    def forward(self, input_ids, lengths):\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, hidden = self.encoder(packed)\n",
    "        sequence_output, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True, total_length=input_ids.size(1))\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        slot_logits = self.slot_classifier(sequence_output)\n",
    "        hidden_cat = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        intent_logits = self.intent_classifier(hidden_cat)\n",
    "        return slot_logits, intent_logits\n",
    "\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "slot_label_size = len(slot2id)\n",
    "intent_label_size = len(intent2id)\n",
    "\n",
    "model = JointRNNModel(vocab_size, embedding_dim, hidden_dim, slot_label_size, intent_label_size).to(device)\n",
    "slot_loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "intent_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -------------------------\n",
    "# 7️⃣ Evaluation\n",
    "# -------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_intent_preds, all_intent_labels = [], []\n",
    "    all_slot_preds, all_slot_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, lengths, slot_labels, intent_labels in loader:\n",
    "            input_ids, lengths = input_ids.to(device), lengths.to(device)\n",
    "            slot_labels, intent_labels = slot_labels.to(device), intent_labels.to(device)\n",
    "\n",
    "            slot_logits, intent_logits = model(input_ids, lengths)\n",
    "\n",
    "            # Intent\n",
    "            intent_preds = torch.argmax(intent_logits, dim=1)\n",
    "            all_intent_preds.extend(intent_preds.cpu().tolist())\n",
    "            all_intent_labels.extend(intent_labels.cpu().tolist())\n",
    "\n",
    "            # Slot\n",
    "            slot_preds = torch.argmax(slot_logits, dim=2)\n",
    "            for i, l in enumerate(lengths):\n",
    "                all_slot_preds.extend(slot_preds[i][:l].cpu().tolist())\n",
    "                all_slot_labels.extend(slot_labels[i][:l].cpu().tolist())\n",
    "\n",
    "    intent_acc = accuracy_score(all_intent_labels, all_intent_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_slot_labels, all_slot_preds, average='micro')\n",
    "    print(f\"Intent Acc: {intent_acc:.4f} | Slot P: {precision:.4f} R: {recall:.4f} F1: {f1:.4f}\")\n",
    "    model.train()\n",
    "    return intent_acc, precision, recall, f1\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, epochs=10, lambda_intent=0.5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for input_ids, lengths, slot_labels, intent_labels in train_loader:\n",
    "            input_ids, lengths = input_ids.to(device), lengths.to(device)\n",
    "            slot_labels, intent_labels = slot_labels.to(device), intent_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            slot_logits, intent_logits = model(input_ids, lengths)\n",
    "\n",
    "            slot_loss = slot_loss_fn(slot_logits.view(-1, slot_logits.shape[-1]), slot_labels.view(-1))\n",
    "            intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "            loss = slot_loss + lambda_intent * intent_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        print(\"=== Validation ===\")\n",
    "        evaluate(model, val_loader)\n",
    "\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, epochs=50)\n",
    "print(\"=== Test Set Evaluation ===\")\n",
    "evaluate(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
